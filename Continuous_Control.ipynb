{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "Project 2 from the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) progrm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_graphics = False\n",
    "use_parallel = False\n",
    "if use_parallel is True:\n",
    "    file_name = '../Reacher_20agents_Windows_x86_64/Reacher.exe'\n",
    "    checkpoint_name = 'checkpoint_20'\n",
    "else:\n",
    "    file_name = '../Reacher_Windows_x86_64/Reacher.exe'\n",
    "    checkpoint_name = 'checkpoint'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=file_name, no_graphics=(not use_graphics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor + Critic\n",
    "\n",
    "Initial definition based on [ddpg-bipedal](https://github.com/udacity/deep-reinforcement-learning/tree/master/ddpg-bipedal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e6)#int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64#128#64#128#32#256#128#64#128#256        # minibatch size\n",
    "GAMMA = 0.97#0.999#0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4#1e-3         # learning rate of the actor \n",
    "LR_CRITIC = 1e-4#3e-4#1e-3        # learning rate of the critic\n",
    "WEIGHT_DECAY = 1e-6#1e-4#0   # L2 weight decay\n",
    "SIGMA = 0.15#0.1#0.85#0.05#0.1#0.2\n",
    "\n",
    "fc1_units = 256#400\n",
    "fc2_units = 128#300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using model from ddpg-pendulum sample\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=400, fc2_units=300):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=400, fc2_units=300):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reusing the `Deep Deterministic Policy Gradients (DDPG)` definition from the lectures.\n",
    "\n",
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed, fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed, fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.hard_copy(self.actor_target, self.actor_local)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed, fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed, fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.hard_copy(self.critic_target, self.critic_local)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        ####self.noise = OUNoise(action_size, random_seed, sigma=SIGMA)\n",
    "        self.noise = OUNoise((num_agents, action_size), random_seed, sigma=SIGMA)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "    \n",
    "    def step(self, states, actions, rewards, next_states, dones, step):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "            self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def hard_copy(self, target, source):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.actor_local.parameters(), 1)\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        # OUNoise should use normal distribution\n",
    "        # https://github.com/udacity/deep-reinforcement-learning/pull/19/files\n",
    "        ####dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.standard_normal(self.size)\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPG\n",
    "\n",
    "Train the Agent with DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1000#2000\n",
    "max_t = 800#700\n",
    "seed = random.random()\n",
    "min_score = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_movel(agent, name='checkpoint'):\n",
    "    torch.save(agent.actor_local.state_dict(), '{}_actor.pth'.format(name))\n",
    "    torch.save(agent.critic_local.state_dict(), '{}_critic.pth'.format(name))\n",
    "\n",
    "def load_movel(agent, name='checkpoint'):\n",
    "    agent.actor_local.load_state_dict(torch.load('{}_actor.pth'.format(name)))\n",
    "    agent.critic_local.load_state_dict(torch.load('{}_critic.pth'.format(name)))\n",
    "\n",
    "def action_scaler_fn(actions, lower: float = -1., upper: float = 1.):\n",
    "    return np.clip(actions, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 4.26\tScore: 14.83\n",
      "Episode 200\tAverage Score: 22.28\tScore: 28.04\n",
      "Episode 300\tAverage Score: 29.70\tScore: 29.48\n",
      "Episode 308\tAverage Score: 30.09\tScore: 31.60\n",
      "Environment solved in 308 episodes!\tAverage Score: 30.09\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=2000, max_t=700):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    max_score = -np.Inf\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states) if use_parallel else agent.act(states[0])\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            if use_parallel is False:\n",
    "                agent.step(states[0], actions[0], rewards[0], next_states[0], dones[0])\n",
    "            else:\n",
    "                for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                    agent.step(state, action, reward, next_state, done, i)\n",
    "            score += rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        current_mean_scores = np.mean(scores_deque)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, current_mean_scores, np.mean(score)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            save_movel(agent, checkpoint_name)\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, current_mean_scores))\n",
    "        if current_mean_scores >= min_score or np.any(dones):\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, current_mean_scores))\n",
    "            save_movel(agent, checkpoint_name)\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = ddpg(n_episodes=n_episodes, max_t=max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 3\n",
    "load_movel(agent, checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 \tScore: 38.899999130517244\n",
      "Episode 2 \tScore: 38.519999139010906\n",
      "Episode 3 \tScore: 38.02999914996326\n",
      "Average score in 3 episodes: 38.483332473163806\n"
     ]
    }
   ],
   "source": [
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "total_score = 0\n",
    "for i_episode in range(1, n_episodes+1):\n",
    "    score = 0\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        env_s = env.step(action)\n",
    "        env_info = env_s[brain_name]\n",
    "        next_state, reward, done = env_info.vector_observations[0], env_info.rewards[0], env_info.local_done[0]\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    print(f\"\\rEpisode {i_episode} \\tScore: {score}\")\n",
    "    total_score += score\n",
    "print(f\"\\rAverage score in {n_episodes} episodes: {total_score/n_episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the environment if you want to see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
